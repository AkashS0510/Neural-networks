{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "iPDnybNl8Kwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obql95xi3vOL"
      },
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "    def __init__(self, sizes):\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y) for y in sizes[1:]]\n",
        "        self.weights = [np.random.randn(y, x)\n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
        "            test_data=None):\n",
        "        if test_data: n_test = len(test_data)\n",
        "        n = len(training_data)\n",
        "        for j in range(epochs):\n",
        "            random.shuffle(training_data)\n",
        "            mini_batches = [\n",
        "                training_data[k:k+mini_batch_size]\n",
        "                for k in range(0, n, mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, eta)\n",
        "            if test_data:\n",
        "                correct_test = self.evaluate(test_data)\n",
        "                correct_train = self.evaluate_train(training_data)\n",
        "                print(\"Epoch {0}: Val {1}/{2} - Accuracy: {3}, Train {4}/{5} - Accuracy: {6}\".format(\n",
        "                    j, correct_test, n_test, round(correct_test / n_test, 3), \n",
        "                    correct_train, len(training_data), round(correct_train / len(training_data), 3)\n",
        "                ))\n",
        "            else:\n",
        "                print(\"Epoch {0} complete\".format(j))\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.biases, nabla_b)]\n",
        "    # BACKPROPAGATION\n",
        "    \n",
        "    def backprop(self, x, y):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        activation = x\n",
        "        activations = [x]\n",
        "        zs = [] \n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b\n",
        "            zs.append(z)\n",
        "            activation = sigmoid(z)\n",
        "            activations.append(activation)\n",
        "        delta = self.cost_derivative(activations[-1], y) * \\\n",
        "            sigmoid_prime(zs[-1])\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta.reshape(-1, 1), activations[-2].reshape(-1, 1).transpose())\n",
        "        for l in range(2, self.num_layers):\n",
        "            z = zs[-l]\n",
        "            sp = sigmoid_prime(z)\n",
        "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta.reshape(-1, 1), activations[-l-1].reshape(-1, 1).transpose())\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "# ACTIVATION FUNCTIONS: \n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "duCE3B0P48cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "Edclht524_tQ",
        "outputId": "4a715fa9-26b7-4b1d-fe67-5c4347e22033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c5f86a9-0ba4-4d84-b12c-e36c540cf3dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c5f86a9-0ba4-4d84-b12c-e36c540cf3dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c5f86a9-0ba4-4d84-b12c-e36c540cf3dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c5f86a9-0ba4-4d84-b12c-e36c540cf3dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(data.data,data.target,test_size=0.33)\n"
      ],
      "metadata": {
        "id": "Mcq4g2Tq5Geq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale=StandardScaler()\n",
        "x_train=scale.fit_transform(x_train)\n",
        "x_test=scale.transform(x_test)"
      ],
      "metadata": {
        "id": "h8ysaxM55ITZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N,D=x_train.shape\n",
        "print(N,D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJB4lsqz5Jtc",
        "outputId": "5f289af9-ed6b-419d-e4cf-8110f4858651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_data=list(zip(x_train,y_train))\n",
        "test_data=list(zip(x_test,y_test))"
      ],
      "metadata": {
        "id": "Yxi4m6Xz6xVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network([D, 16, 2])\n",
        "net.SGD(training_data, 100, 64, 2, test_data=test_data)\n",
        "# SGD(training_data,epochs,batchsize,eta,testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWRi_-Ak5LOr",
        "outputId": "ea1d8eb4-da97-4a44-a662-bde53987977d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Val 106/188 - Accuracy: 0.564, Train 216/381 - Accuracy: 0.567\n",
            "Epoch 1: Val 105/188 - Accuracy: 0.559, Train 196/381 - Accuracy: 0.514\n",
            "Epoch 2: Val 105/188 - Accuracy: 0.559, Train 198/381 - Accuracy: 0.52\n",
            "Epoch 3: Val 104/188 - Accuracy: 0.553, Train 208/381 - Accuracy: 0.546\n",
            "Epoch 4: Val 103/188 - Accuracy: 0.548, Train 210/381 - Accuracy: 0.551\n",
            "Epoch 5: Val 105/188 - Accuracy: 0.559, Train 212/381 - Accuracy: 0.556\n",
            "Epoch 6: Val 106/188 - Accuracy: 0.564, Train 214/381 - Accuracy: 0.562\n",
            "Epoch 7: Val 109/188 - Accuracy: 0.58, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 8: Val 111/188 - Accuracy: 0.59, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 9: Val 113/188 - Accuracy: 0.601, Train 221/381 - Accuracy: 0.58\n",
            "Epoch 10: Val 114/188 - Accuracy: 0.606, Train 221/381 - Accuracy: 0.58\n",
            "Epoch 11: Val 116/188 - Accuracy: 0.617, Train 220/381 - Accuracy: 0.577\n",
            "Epoch 12: Val 116/188 - Accuracy: 0.617, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 13: Val 115/188 - Accuracy: 0.612, Train 226/381 - Accuracy: 0.593\n",
            "Epoch 14: Val 119/188 - Accuracy: 0.633, Train 225/381 - Accuracy: 0.591\n",
            "Epoch 15: Val 118/188 - Accuracy: 0.628, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 16: Val 120/188 - Accuracy: 0.638, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 17: Val 120/188 - Accuracy: 0.638, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 18: Val 121/188 - Accuracy: 0.644, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 19: Val 121/188 - Accuracy: 0.644, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 20: Val 122/188 - Accuracy: 0.649, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 21: Val 123/188 - Accuracy: 0.654, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 22: Val 121/188 - Accuracy: 0.644, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 23: Val 121/188 - Accuracy: 0.644, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 24: Val 120/188 - Accuracy: 0.638, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 25: Val 121/188 - Accuracy: 0.644, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 26: Val 121/188 - Accuracy: 0.644, Train 227/381 - Accuracy: 0.596\n",
            "Epoch 27: Val 122/188 - Accuracy: 0.649, Train 226/381 - Accuracy: 0.593\n",
            "Epoch 28: Val 123/188 - Accuracy: 0.654, Train 227/381 - Accuracy: 0.596\n",
            "Epoch 29: Val 123/188 - Accuracy: 0.654, Train 227/381 - Accuracy: 0.596\n",
            "Epoch 30: Val 120/188 - Accuracy: 0.638, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 31: Val 122/188 - Accuracy: 0.649, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 32: Val 122/188 - Accuracy: 0.649, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 33: Val 122/188 - Accuracy: 0.649, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 34: Val 121/188 - Accuracy: 0.644, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 35: Val 121/188 - Accuracy: 0.644, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 36: Val 121/188 - Accuracy: 0.644, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 37: Val 121/188 - Accuracy: 0.644, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 38: Val 121/188 - Accuracy: 0.644, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 39: Val 121/188 - Accuracy: 0.644, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 40: Val 121/188 - Accuracy: 0.644, Train 235/381 - Accuracy: 0.617\n",
            "Epoch 41: Val 122/188 - Accuracy: 0.649, Train 237/381 - Accuracy: 0.622\n",
            "Epoch 42: Val 122/188 - Accuracy: 0.649, Train 236/381 - Accuracy: 0.619\n",
            "Epoch 43: Val 122/188 - Accuracy: 0.649, Train 236/381 - Accuracy: 0.619\n",
            "Epoch 44: Val 122/188 - Accuracy: 0.649, Train 237/381 - Accuracy: 0.622\n",
            "Epoch 45: Val 122/188 - Accuracy: 0.649, Train 236/381 - Accuracy: 0.619\n",
            "Epoch 46: Val 122/188 - Accuracy: 0.649, Train 236/381 - Accuracy: 0.619\n",
            "Epoch 47: Val 122/188 - Accuracy: 0.649, Train 236/381 - Accuracy: 0.619\n",
            "Epoch 48: Val 122/188 - Accuracy: 0.649, Train 236/381 - Accuracy: 0.619\n",
            "Epoch 49: Val 122/188 - Accuracy: 0.649, Train 235/381 - Accuracy: 0.617\n",
            "Epoch 50: Val 122/188 - Accuracy: 0.649, Train 233/381 - Accuracy: 0.612\n",
            "Epoch 51: Val 123/188 - Accuracy: 0.654, Train 233/381 - Accuracy: 0.612\n",
            "Epoch 52: Val 124/188 - Accuracy: 0.66, Train 233/381 - Accuracy: 0.612\n",
            "Epoch 53: Val 125/188 - Accuracy: 0.665, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 54: Val 126/188 - Accuracy: 0.67, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 55: Val 126/188 - Accuracy: 0.67, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 56: Val 126/188 - Accuracy: 0.67, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 57: Val 126/188 - Accuracy: 0.67, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 58: Val 126/188 - Accuracy: 0.67, Train 232/381 - Accuracy: 0.609\n",
            "Epoch 59: Val 126/188 - Accuracy: 0.67, Train 231/381 - Accuracy: 0.606\n",
            "Epoch 60: Val 126/188 - Accuracy: 0.67, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 61: Val 126/188 - Accuracy: 0.67, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 62: Val 126/188 - Accuracy: 0.67, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 63: Val 126/188 - Accuracy: 0.67, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 64: Val 125/188 - Accuracy: 0.665, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 65: Val 125/188 - Accuracy: 0.665, Train 230/381 - Accuracy: 0.604\n",
            "Epoch 66: Val 126/188 - Accuracy: 0.67, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 67: Val 125/188 - Accuracy: 0.665, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 68: Val 126/188 - Accuracy: 0.67, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 69: Val 126/188 - Accuracy: 0.67, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 70: Val 125/188 - Accuracy: 0.665, Train 229/381 - Accuracy: 0.601\n",
            "Epoch 71: Val 126/188 - Accuracy: 0.67, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 72: Val 126/188 - Accuracy: 0.67, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 73: Val 126/188 - Accuracy: 0.67, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 74: Val 126/188 - Accuracy: 0.67, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 75: Val 126/188 - Accuracy: 0.67, Train 228/381 - Accuracy: 0.598\n",
            "Epoch 76: Val 126/188 - Accuracy: 0.67, Train 227/381 - Accuracy: 0.596\n",
            "Epoch 77: Val 125/188 - Accuracy: 0.665, Train 227/381 - Accuracy: 0.596\n",
            "Epoch 78: Val 126/188 - Accuracy: 0.67, Train 227/381 - Accuracy: 0.596\n",
            "Epoch 79: Val 126/188 - Accuracy: 0.67, Train 226/381 - Accuracy: 0.593\n",
            "Epoch 80: Val 125/188 - Accuracy: 0.665, Train 226/381 - Accuracy: 0.593\n",
            "Epoch 81: Val 125/188 - Accuracy: 0.665, Train 226/381 - Accuracy: 0.593\n",
            "Epoch 82: Val 126/188 - Accuracy: 0.67, Train 224/381 - Accuracy: 0.588\n",
            "Epoch 83: Val 126/188 - Accuracy: 0.67, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 84: Val 126/188 - Accuracy: 0.67, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 85: Val 126/188 - Accuracy: 0.67, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 86: Val 126/188 - Accuracy: 0.67, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 87: Val 126/188 - Accuracy: 0.67, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 88: Val 126/188 - Accuracy: 0.67, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 89: Val 125/188 - Accuracy: 0.665, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 90: Val 124/188 - Accuracy: 0.66, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 91: Val 124/188 - Accuracy: 0.66, Train 223/381 - Accuracy: 0.585\n",
            "Epoch 92: Val 124/188 - Accuracy: 0.66, Train 224/381 - Accuracy: 0.588\n",
            "Epoch 93: Val 124/188 - Accuracy: 0.66, Train 225/381 - Accuracy: 0.591\n",
            "Epoch 94: Val 124/188 - Accuracy: 0.66, Train 225/381 - Accuracy: 0.591\n",
            "Epoch 95: Val 124/188 - Accuracy: 0.66, Train 224/381 - Accuracy: 0.588\n",
            "Epoch 96: Val 124/188 - Accuracy: 0.66, Train 224/381 - Accuracy: 0.588\n",
            "Epoch 97: Val 124/188 - Accuracy: 0.66, Train 224/381 - Accuracy: 0.588\n",
            "Epoch 98: Val 124/188 - Accuracy: 0.66, Train 225/381 - Accuracy: 0.591\n",
            "Epoch 99: Val 124/188 - Accuracy: 0.66, Train 225/381 - Accuracy: 0.591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cr4Q_dqS76b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THg9lsZkByTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}